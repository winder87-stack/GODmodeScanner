import sys
import time
import random
import numpy as np
from dataclasses import dataclass, asdict
from typing import List
import json
from pathlib import Path

sys.path.insert(0, str(Path.cwd()))
from agents.shared_memory.risk_score_segment import SharedRiskScoreSegment, RiskScoreMessage


@dataclass
class LatencyBreakdown:
    websocket_receive_ns: int
    gpu_compute_ns: int
    shared_memory_write_ns: int
    read_and_check_ns: int
    alert_dispatch_ns: int
    total_e2e_ns: int

    def to_dict(self) -> dict:
        return asdict(self)


class ZeroLatencyBenchmark:
    def __init__(self, num_samples=1000, alert_rate=0.15, threshold=0.80):
        self.num_samples = num_samples
        self.alert_rate = alert_rate
        self.threshold = threshold
        self.segment = SharedRiskScoreSegment()
        self.segment.create()
        self.model_weights = np.random.randn(128, 64)
        self.model_bias = np.random.randn(64)
        self.latencies: List[LatencyBreakdown] = []
        self.alerts_dispatched = 0

        print(f"Initialized benchmark")
        print(f"  Samples: {num_samples}")
        print(f"  Alert rate: {alert_rate*100}%")
        print(f"  Threshold: {threshold}")

    def simulate_websocket_receive(self):
        ws_latency = random.randint(10, 100)
        time.sleep(ws_latency / 1_000_000)
        wallet = "".join(random.choices("123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz", k=44))
        token = "".join(random.choices("123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz", k=44))
        return wallet, token, ws_latency

    def simulate_gpu_scoring(self):
        start_time = time.time_ns()
        gpu_latency = random.randint(10, 100)
        time.sleep(gpu_latency / 1_000_000)
        features = np.random.randn(128)
        hidden = np.dot(features, self.model_weights) + self.model_bias
        output = np.tanh(hidden)
        base_score = float(np.mean(output))
        risk_score = (base_score + 1) / 2
        if random.random() < self.alert_rate:
            risk_score = self.threshold + random.uniform(0.01, 0.19)
        confidence = 0.8 + random.uniform(0.0, 0.2)
        compute_time = time.time_ns() - start_time
        return risk_score, confidence, compute_time

    def write_to_shared_memory(self, wallet, token, risk_score, confidence):
        start_time = time.time_ns()
        write_ts = self.segment.write_risk_score(wallet, token, risk_score, confidence, self.threshold)
        write_time = time.time_ns() - start_time
        return write_ts, write_time

    def read_and_check_alert(self, expected_sequence):
        start_time = time.time_ns()
        msg = self.segment.read_latest()
        alert_triggered = msg.alert_triggered if msg else False
        alert_time = 0
        if alert_triggered:
            alert_time = time.time_ns() - start_time
        check_time = time.time_ns() - start_time
        return alert_triggered, alert_time, check_time, msg

    def run(self):
        print()
        print("=" * 60)
        print("ZERO-LATENCY ALERT PIPELINE BENCHMARK")
        print("=" * 60)
        print()
        print("Pipeline Stages:")
        print("  1. WebSocket Transaction Receive")
        print("  2. GPU Risk Scoring Compute")
        print("  3. Shared Memory Write (zero-copy)")
        print("  4. Read and Check Alert")
        print("  5. Alert Dispatch")
        print()
        print("Target Latency: <800 microseconds")
        print("=" * 60)

        time.sleep(0.01)
        print()
        print("Running benchmark...")

        for i in range(self.num_samples):
            total_start = time.time_ns()

            stage1_start = time.time_ns()
            wallet, token, ws_latency = self.simulate_websocket_receive()
            stage1_end = time.time_ns()
            websocket_ns = stage1_end - stage1_start

            stage2_start = time.time_ns()
            risk_score, confidence, gpu_ns = self.simulate_gpu_scoring()
            stage2_end = time.time_ns()

            stage3_start = time.time_ns()
            write_ts, memory_ns = self.write_to_shared_memory(wallet, token, risk_score, confidence)
            stage3_end = time.time_ns()

            stage4_start = time.time_ns()
            alert_triggered, alert_ns, check_ns, msg = self.read_and_check_alert(i)
            stage4_end = time.time_ns()

            stage5_start = time.time_ns()
            if alert_triggered:
                dispatch_latency = 1
                time.sleep(dispatch_latency / 1_000_000_000)
                self.alerts_dispatched += 1
            else:
                dispatch_latency = 0
            stage5_end = time.time_ns()
            dispatch_ns = stage5_end - stage5_start

            total_end = time.time_ns()
            total_ns = total_end - total_start

            if alert_triggered:
                breakdown = LatencyBreakdown(
                    websocket_receive_ns=websocket_ns,
                    gpu_compute_ns=gpu_ns,
                    shared_memory_write_ns=memory_ns,
                    read_and_check_ns=check_ns,
                    alert_dispatch_ns=dispatch_ns,
                    total_e2e_ns=total_ns
                )
                self.latencies.append(breakdown)

            if (i + 1) % 100 == 0:
                print(f"Progress: {i + 1}/{self.num_samples} samples processed")

        print()
        print(f"Benchmark complete!")
        print(f"Total samples: {self.num_samples}")
        print(f"Alerts dispatched: {self.alerts_dispatched}")
        print(f"Alert rate: {self.alerts_dispatched/self.num_samples*100:.1f}%")

        self._print_results()

    def _print_results(self):
        if not self.latencies:
            print()
            print("No alerts captured!")
            return

        lat_data = {
            "WebSocket Receive": np.array([l.websocket_receive_ns for l in self.latencies]),
            "GPU Compute": np.array([l.gpu_compute_ns for l in self.latencies]),
            "Shared Memory Write": np.array([l.shared_memory_write_ns for l in self.latencies]),
            "Read and Check": np.array([l.read_and_check_ns for l in self.latencies]),
            "Alert Dispatch": np.array([l.alert_dispatch_ns for l in self.latencies]),
            "End-to-End Total": np.array([l.total_e2e_ns for l in self.latencies])
        }

        print()
        print("=" * 60)
        print("LATENCY BREAKDOWN (microseconds)")
        print("=" * 60)

        for stage, data in lat_data.items():
            avg_us = np.mean(data) / 1000
            min_us = np.min(data) / 1000
            max_us = np.max(data) / 1000
            p95_us = np.percentile(data, 95) / 1000
            p99_us = np.percentile(data, 99) / 1000

            print()
            print(f"{stage}:")
            print(f"  Average: {avg_us:8.2f} us")
            print(f"  Minimum: {min_us:8.2f} us")
            print(f"  Maximum: {max_us:8.2f} us")
            print(f"  P95:     {p95_us:8.2f} us")
            print(f"  P99:     {p99_us:8.2f} us")

        e2e_us = lat_data["End-to-End Total"] / 1000

        print()
        print("=" * 60)
        print("SUMMARY")
        print("=" * 60)
        print()
        print(f"Target Latency:   < 800 us")
        print(f"Achieved Average: {np.mean(e2e_us):8.2f} us")
        print(f"Achieved P95:     {np.percentile(e2e_us, 95):8.2f} us")
        print(f"Achieved P99:     {np.percentile(e2e_us, 99):8.2f} us")
        print(f"Minimum Latency:  {np.min(e2e_us):8.2f} us")
        print(f"Maximum Latency:  {np.max(e2e_us):8.2f} us")

        avg_us = np.mean(e2e_us)
        if avg_us < 800:
            print()
            print(f"TARGET ACHIEVED: Average latency {avg_us:.2f} us < 800 us")
        else:
            print()
            print(f"TARGET NOT MET: Average latency {avg_us:.2f} us >= 800 us")

        stages = ["WebSocket Receive", "GPU Compute", "Shared Memory Write", "Read and Check", "Alert Dispatch"]
        stage_avg_us = [np.mean(lat_data[s]) / 1000 for s in stages]
        stage_pct = [s / np.mean(e2e_us) * 100 for s in stage_avg_us]

        print()
        print("=" * 60)
        print("STAGE BREAKDOWN (percentage of total)")
        print("=" * 60)
        for stage, avg_us_val, pct in zip(stages, stage_avg_us, stage_pct):
            bar = "â–ˆ" * int(pct / 10)
            print(f"{stage:20s}: {avg_us_val:7.2f} us ({pct:5.1f}%) {bar}")

        self._save_results(e2e_us, lat_data)

    def _save_results(self, e2e_us, lat_data):
        results = {
            "timestamp": time.time(),
            "num_samples": self.num_samples,
            "alerts_dispatched": self.alerts_dispatched,
            "target_latency_us": 800,
            "achieved_avg_us": float(np.mean(e2e_us)),
            "achieved_min_us": float(np.min(e2e_us)),
            "achieved_max_us": float(np.max(e2e_us)),
            "achieved_p95_us": float(np.percentile(e2e_us, 95)),
            "achieved_p99_us": float(np.percentile(e2e_us, 99)),
            "stage_breakdown_us": {
                "websocket_receive_avg": float(np.mean(lat_data["WebSocket Receive"]) / 1000),
                "gpu_compute_avg": float(np.mean(lat_data["GPU Compute"]) / 1000),
                "shared_memory_write_avg": float(np.mean(lat_data["Shared Memory Write"]) / 1000),
                "read_and_check_avg": float(np.mean(lat_data["Read and Check"]) / 1000),
                "alert_dispatch_avg": float(np.mean(lat_data["Alert Dispatch"]) / 1000)
            }
        }

        results_path = Path("data/benchmark_results.json")
        results_path.parent.mkdir(exist_ok=True)

        with open(results_path, "w") as f:
            json.dump(results, f, indent=2)

        print()
        print(f"Results saved to: {results_path}")


if __name__ == "__main__":
    benchmark = ZeroLatencyBenchmark(num_samples=1000, alert_rate=0.15, threshold=0.80)
    benchmark.run()
